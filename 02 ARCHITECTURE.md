
# NEXUS System - Technische Architektur

Vollst√§ndige technische Dokumentation der NEXUS Multi-Agent-Plattform mit **657,453 Zeilen Code** und 10+ spezialisierten Agents.

## üèóÔ∏è System-√úbersicht

### Architektur-Prinzipien
1. **Agent-Spezialisierung**: Jeder Agent hat klar definierte Verantwortlichkeiten
2. **Asynchrone Kommunikation**: Message-Bus-basierte Agent-Interaktion
3. **LLM-Integration**: Ollama-Client f√ºr Code-Generation und Analyse
4. **Modulare Architektur**: Plugin-basierte Erweiterbarkeit
5. **Resilience-First**: Fallback-Mechanismen und Error-Recovery

### Komponenten-Hierarchie
```
NEXUS System
‚îú‚îÄ‚îÄ Core Layer
‚îÇ   ‚îú‚îÄ‚îÄ BaseAgent (Abstract)
‚îÇ   ‚îú‚îÄ‚îÄ MessageBus (Communication Hub)
‚îÇ   ‚îú‚îÄ‚îÄ OllamaClient (LLM Interface)
‚îÇ   ‚îî‚îÄ‚îÄ Configuration Manager
‚îú‚îÄ‚îÄ Agent Layer (10+ Specialized Agents)
‚îÇ   ‚îú‚îÄ‚îÄ Orchestration (Enhanced + Standard)
‚îÇ   ‚îú‚îÄ‚îÄ Code Generation (Backend + Frontend)
‚îÇ   ‚îú‚îÄ‚îÄ Analysis (Analyst + Context)
‚îÇ   ‚îú‚îÄ‚îÄ Quality (QA + Security)
‚îÇ   ‚îú‚îÄ‚îÄ Infrastructure (DevOps + Performance)
‚îÇ   ‚îî‚îÄ‚îÄ Intelligence (Learning + Integration)
‚îî‚îÄ‚îÄ Application Layer
    ‚îú‚îÄ‚îÄ Demo Generator
    ‚îú‚îÄ‚îÄ API Gateway
    ‚îî‚îÄ‚îÄ Monitoring Dashboard
```

## üß† Core Layer

### BaseAgent-Architektur
```python
# /home/ubuntu/nexus/core/base_agent.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional
import asyncio
import logging
import uuid

class BaseAgent(ABC):
    """
    Basis-Klasse f√ºr alle NEXUS-Agents mit standardisierten Interfaces
    """
    
    def __init__(self, agent_id: str, name: str, config: Dict[str, Any]):
        self.agent_id = agent_id
        self.name = name
        self.config = config
        self.logger = logging.getLogger(f"nexus.{agent_id}")
        self.is_initialized = False
        self.message_bus = None
        self.ollama_client = None
    
    @abstractmethod
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """
        Hauptmethode f√ºr Task-Verarbeitung
        Args:
            task: Task-Definition mit type, content, requirements
        Returns:
            Verarbeitungs-Ergebnis mit status, result, metadata
        """
        pass
    
    @abstractmethod  
    def get_capabilities(self) -> List[str]:
        """
        Gibt Liste der Agent-F√§higkeiten zur√ºck
        Returns:
            Liste von capability-strings
        """
        pass
    
    async def initialize(self) -> bool:
        """
        Async Agent-Initialisierung
        Returns:
            True wenn erfolgreich initialisiert
        """
        try:
            await self._setup_ollama_client()
            await self._register_with_message_bus()
            self.is_initialized = True
            self.logger.info(f"Agent {self.agent_id} initialized successfully")
            return True
        except Exception as e:
            self.logger.error(f"Agent {self.agent_id} initialization failed: {e}")
            return False
    
    async def health_check(self) -> Dict[str, Any]:
        """
        Agent-Gesundheitsstatus
        Returns:
            Status-Dictionary mit health, uptime, metrics
        """
        return {
            "agent_id": self.agent_id,
            "name": self.name,
            "status": "healthy" if self.is_initialized else "unhealthy",
            "capabilities": self.get_capabilities(),
            "initialized": self.is_initialized
        }
```

### Message Bus System
```python
# /home/ubuntu/nexus/core/messaging.py
import asyncio
from typing import Dict, Any, Callable, List
import json
from datetime import datetime
import uuid

class Message:
    """
    Standard-Nachrichtenformat f√ºr Agent-Kommunikation
    """
    def __init__(self, 
                 type: str,
                 from_agent: str, 
                 to_agent: str,
                 content: Dict[str, Any],
                 correlation_id: str = None):
        self.id = str(uuid.uuid4())
        self.type = type
        self.from_agent = from_agent
        self.to_agent = to_agent
        self.content = content
        self.correlation_id = correlation_id or self.id
        self.timestamp = datetime.utcnow().isoformat()
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "type": self.type, 
            "from_agent": self.from_agent,
            "to_agent": self.to_agent,
            "content": self.content,
            "correlation_id": self.correlation_id,
            "timestamp": self.timestamp
        }

class MessageBus:
    """
    Zentraler Message-Router f√ºr Agent-Kommunikation
    Features:
    - Asynchrones Message-Routing
    - Agent-Registrierung
    - Message-History
    - Broadcast-Support
    - Error-Handling
    """
    
    def __init__(self):
        self.agents: Dict[str, BaseAgent] = {}
        self.subscribers: Dict[str, List[Callable]] = {}
        self.message_history: List[Dict] = []
        self.is_running = False
        self.message_queue = asyncio.Queue()
    
    async def register_agent(self, agent_id: str, agent: 'BaseAgent'):
        """Agent beim Message Bus registrieren"""
        self.agents[agent_id] = agent
        agent.message_bus = self
        await agent.initialize()
        
    async def send_message(self, message: Message):
        """Message an spezifischen Agent senden"""
        await self.message_queue.put(message)
        
    async def broadcast_message(self, message: Message):
        """Message an alle registrierten Agents senden"""  
        for agent_id in self.agents:
            if agent_id != message.from_agent:
                broadcast_msg = Message(
                    type=message.type,
                    from_agent=message.from_agent,
                    to_agent=agent_id,
                    content=message.content,
                    correlation_id=message.correlation_id
                )
                await self.send_message(broadcast_msg)
    
    async def start_processing(self):
        """Message-Verarbeitung starten"""
        self.is_running = True
        while self.is_running:
            try:
                message = await asyncio.wait_for(
                    self.message_queue.get(), 
                    timeout=1.0
                )
                await self._process_message(message)
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logging.error(f"Message processing error: {e}")
                
    async def _process_message(self, message: Message):
        """Einzelne Message verarbeiten"""
        target_agent = self.agents.get(message.to_agent)
        if target_agent and target_agent.is_initialized:
            try:
                await target_agent.process_task(message.content)
                self.message_history.append(message.to_dict())
            except Exception as e:
                logging.error(f"Agent {message.to_agent} message processing failed: {e}")
```

### Ollama-Client Integration
```python  
# /home/ubuntu/nexus/core/ollama_client.py
import aiohttp
import asyncio
import json
from typing import Dict, Any, List, Optional
import logging

class OllamaClient:
    """
    Asynchroner Ollama-Client f√ºr LLM-Integration
    
    Features:
    - Async HTTP-Requests
    - Model-Fallbacks  
    - Timeout-Handling
    - Health-Monitoring
    - Response-Caching
    """
    
    def __init__(self, base_url: str = "http://localhost:11434", timeout: int = 120):
        self.base_url = base_url.rstrip('/')
        self.timeout = aiohttp.ClientTimeout(total=timeout)
        self.session = None
        self.available_models = []
        self.logger = logging.getLogger("nexus.ollama_client")
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession(timeout=self.timeout)
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def generate(self, 
                      model: str, 
                      prompt: str, 
                      system: Optional[str] = None,
                      temperature: float = 0.1,
                      max_tokens: Optional[int] = None) -> Dict[str, Any]:
        """
        Text-Generation via Ollama
        
        Args:
            model: Modell-Name (z.B. "qwen2.5-coder:7b")
            prompt: User-Prompt
            system: System-Prompt (optional)
            temperature: Kreativit√§t (0.0-1.0) 
            max_tokens: Max Response-L√§nge
            
        Returns:
            Response-Dictionary mit 'response', 'model', 'created_at'
        """
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": temperature
            }
        }
        
        if system:
            payload["system"] = system
        if max_tokens:
            payload["options"]["num_predict"] = max_tokens
            
        try:
            async with self.session.post(
                f"{self.base_url}/api/generate", 
                json=payload
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    self.logger.debug(f"Generated response for model {model}")
                    return result
                else:
                    error_text = await response.text()
                    raise Exception(f"Ollama API error {response.status}: {error_text}")
                    
        except asyncio.TimeoutError:
            self.logger.error(f"Timeout generating with model {model}")
            raise Exception(f"Generation timeout for model {model}")
        except Exception as e:
            self.logger.error(f"Generation failed: {e}")
            raise
    
    async def chat(self, 
                   model: str, 
                   messages: List[Dict[str, str]],
                   temperature: float = 0.1) -> Dict[str, Any]:
        """
        Chat-Completion via Ollama
        
        Args:
            model: Modell-Name
            messages: Liste von {"role": "user/assistant/system", "content": "..."}
            temperature: Kreativit√§t
            
        Returns:
            Chat-Response-Dictionary
        """
        payload = {
            "model": model,
            "messages": messages,
            "stream": False,
            "options": {
                "temperature": temperature
            }
        }
        
        try:
            async with self.session.post(
                f"{self.base_url}/api/chat",
                json=payload
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    return result
                else:
                    error_text = await response.text()
                    raise Exception(f"Chat API error {response.status}: {error_text}")
                    
        except Exception as e:
            self.logger.error(f"Chat failed: {e}")
            raise
    
    async def list_models(self) -> List[Dict[str, Any]]:
        """Verf√ºgbare Modelle auflisten"""
        try:
            async with self.session.get(f"{self.base_url}/api/tags") as response:
                if response.status == 200:
                    data = await response.json()
                    self.available_models = data.get("models", [])
                    return self.available_models
                else:
                    raise Exception(f"Failed to list models: {response.status}")
        except Exception as e:
            self.logger.error(f"Failed to list models: {e}")
            return []
    
    async def check_health(self) -> bool:
        """Ollama-Server-Health pr√ºfen"""
        try:
            async with self.session.get(f"{self.base_url}/") as response:
                return response.status == 200
        except:
            return False
```

## ü§ñ Agent-Layer Architektur

### Enhanced Orchestrator Agent
```python
# /home/ubuntu/nexus/agents/orchestrator_enhanced.py
from core.base_agent import BaseAgent
from core.messaging import Message
from typing import Dict, Any, List
import uuid
import yaml

class EnhancedOrchestratorAgent(BaseAgent):
    """
    Zentraler Orchestrator f√ºr komplexe Multi-Agent-Projekte
    
    Capabilities:
    - Intelligent Project Planning
    - Multi-Agent Task Distribution  
    - Progress Monitoring
    - Quality Gates
    - Resource Management
    """
    
    def __init__(self, config: Dict[str, Any], message_bus):
        super().__init__("orchestrator_enhanced", "Enhanced Project Orchestrator", config)
        self.message_bus = message_bus
        self.active_projects: Dict[str, Dict] = {}
        self.agent_registry: Dict[str, BaseAgent] = {}
        self.project_templates = self._load_project_templates()
        
    def get_capabilities(self) -> List[str]:
        return [
            "project_planning",
            "multi_agent_coordination", 
            "progress_tracking",
            "quality_gates",
            "resource_allocation",
            "dependency_management",
            "risk_assessment",
            "performance_optimization"
        ]
    
    async def process_project_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """
        Vollst√§ndige Projekt-Erstellung koordinieren
        
        Args:
            request: {
                "type": "fullstack_webapp",
                "name": "Project Name",
                "description": "...",
                "technologies": {...},
                "features": [...]
            }
            
        Returns:
            Project-Result mit project_id, status, artifacts
        """
        project_id = str(uuid.uuid4())
        
        try:
            # 1. Project Planning Phase
            project_plan = await self._create_project_plan(request)
            self.active_projects[project_id] = {
                "request": request,
                "plan": project_plan,
                "status": "planning", 
                "artifacts": {},
                "metrics": {}
            }
            
            # 2. Agent Assignment & Task Distribution
            await self._assign_agents(project_id, project_plan)
            
            # 3. Backend Generation Phase
            if "backend" in project_plan["phases"]:
                backend_result = await self._coordinate_backend_generation(project_id)
                self.active_projects[project_id]["artifacts"]["backend"] = backend_result
                
            # 4. Frontend Generation Phase  
            if "frontend" in project_plan["phases"]:
                frontend_result = await self._coordinate_frontend_generation(project_id)
                self.active_projects[project_id]["artifacts"]["frontend"] = frontend_result
            
            # 5. Integration & Testing Phase
            integration_result = await self._coordinate_integration(project_id)
            self.active_projects[project_id]["artifacts"]["integration"] = integration_result
            
            # 6. Quality Gates & Validation
            qa_result = await self._coordinate_quality_assurance(project_id)
            
            # 7. Deployment Preparation
            deployment_artifacts = await self._prepare_deployment(project_id)
            
            self.active_projects[project_id]["status"] = "completed"
            
            return {
                "project_id": project_id,
                "status": "success",
                "project_path": f"/home/ubuntu/nexus/demo/{project_id}",
                "artifacts": self.active_projects[project_id]["artifacts"],
                "metrics": self._calculate_project_metrics(project_id),
                "deployment_ready": True
            }
            
        except Exception as e:
            self.active_projects[project_id]["status"] = "failed"
            self.active_projects[project_id]["error"] = str(e)
            self.logger.error(f"Project {project_id} failed: {e}")
            
            return {
                "project_id": project_id,
                "status": "failed",
                "error": str(e),
                "partial_artifacts": self.active_projects[project_id].get("artifacts", {})
            }
    
    async def _create_project_plan(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """LLM-basierte intelligente Projektplanung"""
        system_prompt = """
        Du bist ein Senior Software Architect. Erstelle einen detaillierten Projektplan.
        Analysiere die Anforderungen und erstelle eine optimale Agent-Verteilung.
        
        Beachte:
        - Verf√ºgbare Agents: Backend, Frontend, QA, Security, Performance, DevOps
        - Technologie-Constraints
        - Abh√§ngigkeiten zwischen Components
        - Quality Gates
        - Performance Requirements
        """
        
        user_prompt = f"""
        Project Request:
        Name: {request.get('name', 'Unnamed Project')}
        Type: {request.get('type', 'generic')}
        Description: {request.get('description', '')}
        Technologies: {request.get('technologies', {})}
        Features: {request.get('features', [])}
        
        Erstelle einen strukturierten Projektplan mit:
        1. Phasen-Definition
        2. Agent-Assignment
        3. Task-Dependencies
        4. Quality-Gates
        5. Zeitsch√§tzungen
        
        Output als JSON.
        """
        
        try:
            async with self.ollama_client as client:
                response = await client.generate(
                    model=self.config['ollama']['models']['orchestrator'],
                    system=system_prompt,
                    prompt=user_prompt,
                    temperature=0.1
                )
                
                # Parse LLM Response zu Project Plan
                plan_text = response['response']
                # JSON parsing logic hier...
                
                return self._parse_project_plan(plan_text)
                
        except Exception as e:
            self.logger.error(f"LLM project planning failed: {e}")
            # Fallback zu Template-basiertem Planning
            return self._template_based_planning(request)
    
    async def _coordinate_backend_generation(self, project_id: str) -> Dict[str, Any]:
        """Backend-Generation durch BackendEnhancedAgent koordinieren"""
        project = self.active_projects[project_id]
        backend_task = {
            "type": "generate_backend",
            "project_id": project_id,
            "specifications": project["plan"]["backend_specs"],
            "technologies": project["request"]["technologies"].get("backend", "fastapi"),
            "features": [f for f in project["request"]["features"] if "backend" in f or "api" in f]
        }
        
        # Message an Backend Agent senden
        message = Message(
            type="task_request",
            from_agent=self.agent_id,
            to_agent="backend_enhanced",
            content=backend_task,
            correlation_id=project_id
        )
        
        await self.message_bus.send_message(message)
        
        # Warten auf Backend-Result (vereinfacht)
        # In echter Implementation w√ºrde hier async waiting mit timeout erfolgen
        return {"status": "generated", "path": f"demo/{project_id}/backend"}
```

### Backend Enhanced Agent
```python  
# /home/ubuntu/nexus/agents/backend_enhanced.py
from fastapi import FastAPI, HTTPException, Depends
from sqlalchemy import create_engine, Column, Integer, String, DateTime, Boolean
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, Session
from pydantic import BaseModel
from typing import List, Optional
import uvicorn
from core.base_agent import BaseAgent

class BackendEnhancedAgent(BaseAgent):
    """
    Erweiterte Backend-Generation mit FastAPI + SQLAlchemy
    
    Features:
    - FastAPI Application Generation
    - SQLAlchemy Model Creation
    - Pydantic Schema Generation
    - CRUD Operations
    - Authentication Integration
    - API Documentation
    - Docker Containerization
    - Database Migrations
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__("backend_enhanced", "Enhanced Backend Developer", config)
        self.supported_frameworks = ["fastapi", "flask", "django"]
        self.supported_databases = ["postgresql", "sqlite", "mysql", "mongodb"]
        
    def get_capabilities(self) -> List[str]:
        return [
            "fastapi_applications",
            "sqlalchemy_models", 
            "pydantic_schemas",
            "crud_operations",
            "jwt_authentication",
            "oauth2_integration",
            "file_upload_handling",
            "background_tasks",
            "database_migrations",
            "api_documentation",
            "docker_containerization",
            "unit_test_generation",
            "performance_optimization"
        ]
    
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Backend-Generation Task verarbeiten"""
        if task["type"] == "generate_backend":
            return await self._generate_backend_application(task)
        elif task["type"] == "generate_api":
            return await self._generate_api_endpoints(task)
        elif task["type"] == "generate_models":
            return await self._generate_database_models(task)
        else:
            raise ValueError(f"Unsupported task type: {task['type']}")
    
    async def _generate_backend_application(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Vollst√§ndige FastAPI-Application generieren"""
        project_id = task["project_id"]
        specifications = task["specifications"]
        
        # LLM f√ºr Code-Generation verwenden
        system_prompt = """
        Du bist ein Expert FastAPI Developer. Generiere production-ready FastAPI Code.
        
        Standards:
        - Async/await patterns
        - Proper error handling
        - Pydantic models for validation
        - SQLAlchemy for database
        - JWT authentication
        - CORS configuration
        - OpenAPI documentation
        - Docker deployment ready
        """
        
        user_prompt = f"""
        Generiere eine vollst√§ndige FastAPI Application:
        
        Specifications: {specifications}
        Features: {task.get('features', [])}
        Database: {task.get('technologies', {}).get('database', 'sqlite')}
        
        Erstelle:
        1. main.py - FastAPI app with routing
        2. models.py - SQLAlchemy models
        3. schemas.py - Pydantic schemas  
        4. crud.py - Database operations
        5. auth.py - Authentication logic
        6. database.py - Database connection
        7. requirements.txt - Dependencies
        8. Dockerfile - Container setup
        
        Vollst√§ndiger, funktionsf√§higer Code!
        """
        
        try:
            async with self.ollama_client as client:
                response = await client.generate(
                    model=self.config['ollama']['models']['backend'],
                    system=system_prompt,
                    prompt=user_prompt,
                    temperature=0.1,
                    max_tokens=4000
                )
                
                generated_code = response['response']
                
                # Code-Files auf Disk schreiben
                backend_path = f"/home/ubuntu/nexus/demo/{project_id}/backend"
                files_created = await self._write_backend_files(backend_path, generated_code)
                
                return {
                    "status": "success",
                    "backend_path": backend_path, 
                    "files_created": files_created,
                    "framework": "fastapi",
                    "database": task.get('technologies', {}).get('database', 'sqlite')
                }
                
        except Exception as e:
            self.logger.error(f"Backend generation failed: {e}")
            # Fallback zu Template-basierter Generation
            return await self._template_based_backend(task)
            
    async def _write_backend_files(self, backend_path: str, generated_code: str) -> List[str]:
        """Generierte Backend-Files auf Disk schreiben"""
        import os
        import re
        
        os.makedirs(backend_path, exist_ok=True)
        
        files_created = []
        
        # FastAPI Main Application
        main_py_content = f'''
from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
import uvicorn
from database import SessionLocal, engine
import models
import crud
import schemas
from auth import verify_token

# Create database tables
models.Base.metadata.create_all(bind=engine)

app = FastAPI(
    title="Generated Backend API",
    description="Auto-generated FastAPI application",
    version="1.0.0"
)

# CORS configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:8080"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Dependency for database session
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

security = HTTPBearer()

@app.get("/")
def read_root():
    return {{"message": "Backend API is running"}}

@app.get("/health")
def health_check():
    return {{"status": "healthy", "service": "backend-api"}}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''
        
        with open(f"{backend_path}/main.py", "w", encoding="utf-8") as f:
            f.write(main_py_content)
        files_created.append("main.py")
        
        # SQLAlchemy Models
        models_py_content = f'''
from sqlalchemy import Column, Integer, String, DateTime, Boolean, Text, ForeignKey
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func

Base = declarative_base()

class User(Base):
    __tablename__ = "users"
    
    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True, index=True)
    email = Column(String, unique=True, index=True) 
    hashed_password = Column(String)
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())

class Item(Base):
    __tablename__ = "items"
    
    id = Column(Integer, primary_key=True, index=True)
    title = Column(String, index=True)
    description = Column(Text)
    owner_id = Column(Integer, ForeignKey("users.id"))
    is_completed = Column(Boolean, default=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    
    owner = relationship("User")
'''
        
        with open(f"{backend_path}/models.py", "w", encoding="utf-8") as f:
            f.write(models_py_content)
        files_created.append("models.py")
        
        # Requirements.txt
        requirements_content = f'''
fastapi==0.104.1
uvicorn[standard]==0.24.0
sqlalchemy==2.0.23
pydantic==2.5.0
python-multipart==0.0.6
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
alembic==1.13.1
psycopg2-binary==2.9.9
python-dotenv==1.0.0
'''
        
        with open(f"{backend_path}/requirements.txt", "w", encoding="utf-8") as f:
            f.write(requirements_content)
        files_created.append("requirements.txt")
        
        # Dockerfile
        dockerfile_content = f'''
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
'''
        
        with open(f"{backend_path}/Dockerfile", "w", encoding="utf-8") as f:
            f.write(dockerfile_content)
        files_created.append("Dockerfile")
        
        return files_created
```

### Frontend Enhanced Agent
```python
# /home/ubuntu/nexus/agents/frontend_enhanced.py (Mit Bug-Fix)
from core.base_agent import BaseAgent
from typing import Dict, Any, List
import os
import json

class FrontendEnhancedAgent(BaseAgent):
    """
    Enhanced Frontend Agent f√ºr moderne React/TypeScript Applications
    
    KNOWN BUG (FIXED):
    - Line 1052: JavaScript code in Python f-string
    - Line 1055: JavaScript ternary operator in f-string
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__("frontend_enhanced", "Enhanced Frontend Developer", config)
        
    def get_capabilities(self) -> List[str]:
        return [
            "react_typescript",
            "modern_hooks",
            "state_management",
            "responsive_design", 
            "component_library",
            "routing",
            "form_handling",
            "api_integration",
            "testing",
            "build_optimization"
        ]
    
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Frontend-Generation Task verarbeiten"""
        if task["type"] == "generate_frontend":
            return await self._generate_react_application(task)
        else:
            raise ValueError(f"Unsupported task type: {task['type']}")
            
    async def _generate_todo_component(self) -> str:
        """
        BUG-FIX: Korrigierte Todo-Component ohne JavaScript-Syntax in Python
        
        Original Bug (Line 1052):
        Active ({todos.filter(t => !t.completed).length})
        
        Fixed Version: Proper Python string formatting
        """
        
        # FIXED: Separate JavaScript logic from Python template
        component_template = '''
import React, { useState, useEffect } from 'react';
import './TodoApp.css';

interface Todo {
  id: string;
  text: string; 
  completed: boolean;
  createdAt: Date;
}

const TodoApp: React.FC = () => {
  const [todos, setTodos] = useState<Todo[]>([]);
  const [inputText, setInputText] = useState('');
  const [filter, setFilter] = useState<'all' | 'active' | 'completed'>('all');

  const addTodo = () => {
    if (inputText.trim()) {
      const newTodo: Todo = {
        id: Date.now().toString(),
        text: inputText.trim(),
        completed: false,
        createdAt: new Date()
      };
      setTodos([...todos, newTodo]);
      setInputText('');
    }
  };

  const toggleTodo = (id: string) => {
    setTodos(todos.map(todo => 
      todo.id === id ? { ...todo, completed: !todo.completed } : todo
    ));
  };

  const deleteTodo = (id: string) => {
    setTodos(todos.filter(todo => todo.id !== id));
  };

  const filteredTodos = todos.filter(todo => {
    if (filter === 'active') return !todo.completed;
    if (filter === 'completed') return todo.completed;
    return true;
  });

  // FIXED: Proper JavaScript logic separated from Python
  const activeTodosCount = todos.filter(todo => !todo.completed).length;

  return (
    <div className="todo-app">
      <h1>Todo Application</h1>
      
      <div className="todo-input">
        <input
          type="text"
          value={inputText}
          onChange={(e) => setInputText(e.target.value)}
          onKeyPress={(e) => e.key === 'Enter' && addTodo()}
          placeholder="Add a new todo..."
        />
        <button onClick={addTodo}>Add</button>
      </div>

      <div className="todo-filters">
        <button 
          className={`filter-btn ${filter === 'all' ? 'active' : ''}`}
          onClick={() => setFilter('all')}
        >
          All ({todos.length})
        </button>
        <button 
          className={`filter-btn ${filter === 'active' ? 'active' : ''}`}
          onClick={() => setFilter('active')}
        >
          Active ({activeTodosCount})
        </button>
        <button 
          className={`filter-btn ${filter === 'completed' ? 'active' : ''}`}
          onClick={() => setFilter('completed')}
        >
          Completed ({todos.length - activeTodosCount})
        </button>
      </div>

      <div className="todo-list">
        {filteredTodos.map(todo => (
          <div key={todo.id} className={`todo-item ${todo.completed ? 'completed' : ''}`}>
            <input
              type="checkbox"
              checked={todo.completed}
              onChange={() => toggleTodo(todo.id)}
            />
            <span className="todo-text">{todo.text}</span>
            <button 
              className="delete-btn"
              onClick={() => deleteTodo(todo.id)}
            >
              Delete
            </button>
          </div>
        ))}
      </div>
    </div>
  );
};

export default TodoApp;
'''
        
        return component_template
```

## üìä Specialized Agent-Layer

### Context Agent mit Memory-Management
```python
# /home/ubuntu/nexus/agents/context/agent.py
from core.base_agent import BaseAgent
import sqlite3
import json
from typing import Dict, Any, List, Optional
from datetime import datetime

class ContextAgent(BaseAgent):
    """
    Kontext- und Memory-Management f√ºr Agent-Kommunikation
    
    Verzeichnisstruktur:
    - analyzers/: Kontext-Analyse-Module
    - chunkers/: Text-Segmentierung
    - memory/: Persistente Speicherung
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__("context", "Context & Memory Manager", config)
        self.memory_db_path = "/home/ubuntu/nexus/knowledge/learning.db"
        self._init_memory_database()
    
    def get_capabilities(self) -> List[str]:
        return [
            "context_analysis",
            "memory_storage", 
            "conversation_tracking",
            "semantic_search",
            "knowledge_extraction",
            "entity_recognition",
            "relationship_mapping"
        ]
    
    def _init_memory_database(self):
        """Memory-Database initialisieren"""
        with sqlite3.connect(self.memory_db_path) as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS conversations (
                    id TEXT PRIMARY KEY,
                    agent_from TEXT,
                    agent_to TEXT,
                    content TEXT,
                    context_vector TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            conn.execute('''
                CREATE TABLE IF NOT EXISTS knowledge_base (
                    id TEXT PRIMARY KEY,
                    topic TEXT,
                    content TEXT,
                    confidence REAL,
                    source_agent TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
```

### Performance Agent mit Monitoring
```python
# /home/ubuntu/nexus/agents/performance/agent.py
import psutil
import asyncio
import time
from typing import Dict, Any, List
from core.base_agent import BaseAgent

class PerformanceAgent(BaseAgent):
    """
    System- und Application-Performance-Monitoring
    
    Bekannte TODOs:
    - Line ~45: "TODO: Implement continuous monitoring loop"
    - Line ~78: "TODO: Implement comprehensive monitoring loop"
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__("performance", "Performance Monitor", config)
        self.metrics_history = []
        self.alert_thresholds = {
            "cpu_usage": 80.0,
            "memory_usage": 85.0,
            "disk_usage": 90.0
        }
    
    def get_capabilities(self) -> List[str]:
        return [
            "real_time_monitoring",
            "performance_profiling",
            "bottleneck_detection", 
            "scaling_recommendations",
            "alert_management",
            "metrics_collection",
            "capacity_planning"
        ]
    
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        if task["type"] == "start_monitoring":
            return await self._start_continuous_monitoring()
        elif task["type"] == "get_metrics":
            return await self._collect_current_metrics()
        else:
            raise ValueError(f"Unsupported task type: {task['type']}")
    
    async def _start_continuous_monitoring(self) -> Dict[str, Any]:
        """
        TODO: Implement continuous monitoring loop
        
        Should include:
        - Real-time metrics collection
        - Threshold-based alerting
        - Performance trending
        - Automated scaling recommendations
        """
        # PLACEHOLDER: Kontinuierliches Monitoring implementieren
        return {
            "status": "monitoring_started",
            "note": "TODO: Full implementation needed"
        }
    
    async def _collect_current_metrics(self) -> Dict[str, Any]:
        """Aktuelle System-Metriken sammeln"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        metrics = {
            "timestamp": time.time(),
            "cpu_usage": cpu_percent,
            "memory_usage": memory.percent,
            "memory_available": memory.available,
            "disk_usage": disk.percent,
            "disk_free": disk.free
        }
        
        self.metrics_history.append(metrics)
        
        # Alert-Check
        alerts = self._check_thresholds(metrics)
        
        return {
            "status": "success",
            "metrics": metrics,
            "alerts": alerts,
            "trends": self._calculate_trends()
        }
    
    def _check_thresholds(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Threshold-basierte Alerts pr√ºfen"""
        alerts = []
        
        for metric, threshold in self.alert_thresholds.items():
            if metrics.get(metric, 0) > threshold:
                alerts.append({
                    "type": "threshold_exceeded",
                    "metric": metric,
                    "value": metrics[metric],
                    "threshold": threshold,
                    "severity": "warning" if metrics[metric] < threshold * 1.1 else "critical"
                })
                
        return alerts
```

### QA Agent mit Testing-Framework
```python
# /home/ubuntu/nexus/agents/qa/agent.py
from core.base_agent import BaseAgent
from typing import Dict, Any, List
import ast
import subprocess
import os

class QAAgent(BaseAgent):
    """
    Quality Assurance Agent mit automatisierter Code-Analyse
    
    Verzeichnisstruktur:
    - testing/: Test-Generation und -Ausf√ºhrung
    - review/: Code-Review-Automatisierung  
    - refactoring/: Code-Verbesserungs-Vorschl√§ge
    - metrics/: Qualit√§ts-Metriken
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__("qa", "Quality Assurance Specialist", config)
        
    def get_capabilities(self) -> List[str]:
        return [
            "code_quality_analysis",
            "automated_testing",
            "security_scanning",
            "performance_profiling", 
            "refactoring_suggestions",
            "documentation_generation",
            "compliance_checking"
        ]
    
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        if task["type"] == "analyze_code_quality":
            return await self._analyze_code_quality(task["code_path"])
        elif task["type"] == "generate_tests":
            return await self._generate_tests(task["source_code"])
        else:
            raise ValueError(f"Unsupported task type: {task['type']}")
    
    async def _analyze_code_quality(self, code_path: str) -> Dict[str, Any]:
        """Code-Qualit√§t analysieren"""
        quality_metrics = {
            "complexity": self._calculate_complexity(code_path),
            "test_coverage": self._calculate_test_coverage(code_path),
            "code_smells": self._detect_code_smells(code_path),
            "security_issues": self._scan_security_issues(code_path),
            "documentation_score": self._calculate_documentation_score(code_path)
        }
        
        overall_score = self._calculate_overall_quality_score(quality_metrics)
        
        return {
            "status": "analysis_complete",
            "path": code_path,
            "metrics": quality_metrics,
            "overall_score": overall_score,
            "recommendations": self._generate_improvement_recommendations(quality_metrics)
        }
    
    def _calculate_complexity(self, code_path: str) -> Dict[str, Any]:
        """Cyclomatic Complexity berechnen"""
        try:
            result = subprocess.run(
                ["radon", "cc", code_path, "-j"],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                return {"radon_output": result.stdout, "status": "success"}
            else:
                return {"status": "failed", "error": result.stderr}
                
        except subprocess.TimeoutExpired:
            return {"status": "timeout"}
        except FileNotFoundError:
            # Fallback: Simple AST-based complexity
            return self._simple_complexity_analysis(code_path)
    
    def _simple_complexity_analysis(self, code_path: str) -> Dict[str, Any]:
        """Einfache Complexity-Analyse mit AST"""
        complexity_score = 0
        
        try:
            with open(code_path, 'r', encoding='utf-8') as f:
                tree = ast.parse(f.read())
                
            for node in ast.walk(tree):
                # Z√§hle Verzweigungen (if, for, while, etc.)
                if isinstance(node, (ast.If, ast.For, ast.While, ast.Try)):
                    complexity_score += 1
                elif isinstance(node, ast.FunctionDef):
                    complexity_score += 1
                    
            return {
                "complexity_score": complexity_score,
                "status": "success",
                "method": "ast_analysis"
            }
            
        except Exception as e:
            return {"status": "failed", "error": str(e)}
```

## üîí Security & Integration Layer

### Security Agent
```python
# /home/ubuntu/nexus/agents/security_agent.py
from core.base_agent import BaseAgent
import re
import hashlib
from typing import Dict, Any, List

class SecurityAgent(BaseAgent):
    """
    Sicherheits-Validierung und Vulnerability-Scanning
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__("security", "Security Specialist", config)
        self.vulnerability_patterns = self._load_vulnerability_patterns()
    
    def get_capabilities(self) -> List[str]:
        return [
            "code_security_scanning",
            "dependency_vulnerability_check",
            "authentication_validation",
            "input_sanitization_check",
            "sql_injection_detection",
            "xss_prevention_check",
            "secrets_detection"
        ]
    
    def _load_vulnerability_patterns(self) -> Dict[str, List[str]]:
        """Bekannte Vulnerability-Patterns laden"""
        return {
            "sql_injection": [
                r"SELECT.*FROM.*WHERE.*\+.*",
                r"INSERT.*INTO.*VALUES.*\+.*",
                r"UPDATE.*SET.*\+.*",
                r"DELETE.*FROM.*WHERE.*\+.*"
            ],
            "xss": [
                r"<script>.*</script>",
                r"javascript:",
                r"on\w+\s*="
            ],
            "hardcoded_secrets": [
                r"password\s*=\s*['\"].*['\"]",
                r"api_key\s*=\s*['\"].*['\"]",
                r"secret_key\s*=\s*['\"].*['\"]"
            ]
        }
    
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        if task["type"] == "security_scan":
            return await self._perform_security_scan(task["code_path"])
        else:
            raise ValueError(f"Unsupported task type: {task['type']}")
    
    async def _perform_security_scan(self, code_path: str) -> Dict[str, Any]:
        """Vollst√§ndiger Security-Scan"""
        vulnerabilities = []
        
        # Code-Dateien scannen
        for root, dirs, files in os.walk(code_path):
            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    file_vulns = self._scan_file_vulnerabilities(file_path)
                    vulnerabilities.extend(file_vulns)
        
        security_score = self._calculate_security_score(vulnerabilities)
        
        return {
            "status": "scan_complete",
            "code_path": code_path,
            "vulnerabilities": vulnerabilities,
            "security_score": security_score,
            "recommendations": self._generate_security_recommendations(vulnerabilities)
        }
```

## üöÄ Deployment & Configuration

### Configuration Management
```yaml
# /home/ubuntu/nexus_config.yaml - Production Configuration
nexus:
  version: "2.0.0"
  environment: "production"  
  project_root: "/home/ubuntu/nexus"
  demo_output: "/home/ubuntu/nexus/demo"
  log_level: "INFO"

ollama:
  base_url: "http://localhost:11434"
  timeout: 120
  health_check_interval: 30
  models:
    orchestrator: "qwen2.5-coder:7b"
    backend: "codellama:7b" 
    frontend: "qwen2.5-coder:7b"
    analyst: "deepseek-coder:6.7b"
    qa: "qwen2.5-coder:7b"
    security: "codellama:7b"
  model_fallbacks:
    primary: "qwen2.5-coder:7b"
    secondary: "codellama:7b"
    minimal: "qwen2:1.5b"

agents:
  orchestrator:
    max_concurrent_projects: 5
    task_timeout: 300
    planning_depth: 3
    quality_gates_enabled: true
    
  backend:
    technologies: ["fastapi", "flask", "django"]
    databases: ["postgresql", "sqlite", "mysql", "mongodb"]
    auth_methods: ["jwt", "oauth2", "session"]
    testing_framework: ["pytest", "unittest"]
    
  frontend:
    technologies: ["react", "vue", "svelte", "vanilla"]
    typescript_enabled: true
    styling: ["tailwind", "styled-components", "css-modules"]
    state_management: ["redux", "zustand", "context"]
    
  performance:
    monitoring_enabled: true
    metrics_collection_interval: 60
    alert_thresholds:
      cpu_usage: 80.0
      memory_usage: 85.0
      disk_usage: 90.0
    
  security:
    scanning_enabled: true
    dependency_check: true
    vulnerability_database_update: "daily"
    
  qa:
    automated_testing: true
    code_coverage_threshold: 80.0
    complexity_threshold: 10
    documentation_required: true

message_bus:
  max_queue_size: 1000
  message_timeout: 60
  retry_attempts: 3
  dead_letter_queue_enabled: true

database:
  knowledge_db: "/home/ubuntu/nexus/knowledge/learning.db"
  performance_logs: "/home/ubuntu/nexus/logs/performance.log"
  audit_logs: "/home/ubuntu/nexus/logs/audit.log"

deployment:
  docker_enabled: true
  kubernetes_manifests: true
  nginx_config: true
  ssl_enabled: true
  monitoring_stack: ["prometheus", "grafana"]
```

## üìà Performance & Scalability

### System Performance Characteristics
```python
# Performance Benchmarks (aus logs/performance.log)
PERFORMANCE_METRICS = {
    "project_generation": {
        "simple_todo_app": "45-90 seconds",
        "fullstack_webapp": "2-5 minutes", 
        "enterprise_system": "8-15 minutes"
    },
    "llm_response_times": {
        "qwen2.5-coder:7b": "1.2-2.8 seconds",
        "codellama:7b": "0.8-2.1 seconds",
        "deepseek-coder:6.7b": "1.5-3.2 seconds"
    },
    "memory_usage": {
        "base_system": "512MB-1GB",
        "with_large_models": "2-4GB", 
        "peak_generation": "6-8GB"
    },
    "concurrent_projects": {
        "recommended_max": 5,
        "tested_max": 10,
        "stability_threshold": 3
    }
}
```

### Horizontal Scaling Architecture
```
Production Deployment:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Load Balancer  ‚îÇ    ‚îÇ  NEXUS Gateway  ‚îÇ    ‚îÇ  Agent Cluster  ‚îÇ
‚îÇ   (nginx/HAP)   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   (FastAPI)     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   (Docker)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ                       ‚îÇ
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ  Message Queue  ‚îÇ    ‚îÇ  Ollama Cluster ‚îÇ
                       ‚îÇ   (Redis/Rabbit)‚îÇ    ‚îÇ   (GPU Nodes)   ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ   Monitoring    ‚îÇ
                       ‚îÇ(Prometheus/Graf)‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîç Error Handling & Resilience

### Fallback-Strategien
1. **LLM Unavailable**: Template-basierte Code-Generation
2. **Model Not Found**: Automatischer Fallback zu verf√ºgbaren Modellen
3. **Network Issues**: Exponential Backoff Retry-Logic
4. **Memory Constraints**: Graceful Degradation mit kleineren Modellen
5. **Agent Failures**: Isolation und Recovery-Mechanismen

### Bekannte Limitationen
1. **Frontend Agent**: JavaScript-Syntax-Konflikte in Python-Templates
2. **Async Initialization**: Race-Conditions bei komplexer Agent-Startup-Sequenz
3. **Test Suite**: Import-Chain-Failures durch Syntax-Errors
4. **Performance Monitoring**: Unvollst√§ndige Implementierung kontinuierlicher √úberwachung
5. **Context Memory**: Begrenzte Langzeit-Persistierung von Konversations-History

---

**NEXUS Architecture v2.0.0** - Designed for Production-Scale Multi-Agent Orchestration

**Technical Foundation**: 657,453 Lines | 10+ Agents | FastAPI + Ollama + SQLAlchemy | Docker-Ready
